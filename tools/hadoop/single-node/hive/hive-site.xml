<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>  
    <property>
        <name>hadoop.embedded.local.mode</name>
        <value>false</value>
    </property>
    <!--
    <property>
        <name>fs.default.name</name>
        <value>hdfs://laomie-E431:9000</value>
    </property>
    -->
    <property>
        <name>mapred.job.tracker</name>
        <value>laomie-E431:8021</value>
    </property>
    <property>  
        <name>javax.jdo.option.ConnectionURL</name>  
        <value>jdbc:mysql://localhost/hadoop2?createDatabaseIfNotExist=true</value>  
    </property>    
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>hdfs://laomie-E431:9000/hive/warehouse</value>
    </property>
    <property>
        <name>hive.exec.scratchdir</name>
        <value>hdfs://laomie-E431:9000/hive/scratchdir</value>
    </property>
    <property>
        <name>hive.querylog.location</name>
        <value>/usr/local/apache/hive/logs</value>
    </property>  
    <property>  
        <name>javax.jdo.option.ConnectionDriverName</name>  
        <value>com.mysql.jdbc.Driver</value>  
    </property>  
    <property>  
        <name>javax.jdo.option.ConnectionUserName</name>  
        <value>hadoop</value>  
    </property>  
    <property>  
        <name>javax.jdo.option.ConnectionPassword</name>  
        <value>hadoop</value>  
    </property> 
    <!--
    <property>
      <name>hive.zookeeper.quorum</name>
      <value>localhost</value>
      <description>The list of zookeeper servers to talk to. This is only needed for read/write locks.</description>
    </property>
    -->
    <property>
        <name>hive.exec.parallel</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.parallel.thread.number</name>
        <value>30</value>
    </property>
    <property>
        <name>hive.start.cleanup.scratchdir</name>
        <value>true</value>
    </property>  
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10006</value>
    </property>
    <property>
        <name>hive.hwi.war.file</name>
        <value>lib/hive-hwi-1.0.0.jar</value>
        <description>This sets the path to the HWI war file, relative to ${HIVE_HOME}. </description>
    </property>
    <property>
        <name>hive.hwi.listen.host</name>
        <value>0.0.0.0</value>
        <description>This is the host address the Hive Web Interface will listen on</description>
    </property>
    <property>
        <name>hive.hwi.listen.port</name>
        <value>9999</value>
        <description>This is the port the Hive Web Interface will listen on</description>
    </property>
    <property>
        <name>hive.fetch.task.conversion</name>
        <value>more</value>
    </property>
    <property>
        <name>hive.optimize.index.groupby</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.join.cache.size</name>
        <value>250000</value>
    </property>
    <property>
        <name>hive.mapjoin.bucket.cache.size</name>
        <value>10000</value>
    </property>
    <!--
    <property>
        <name>hive.cli.print.current.db</name>
        <value>true</value>
    </property>
    -->
    <property>
        <name>hive.stats.autogather</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.mapred.reduce.tasks.speculative.execution</name>
        <value>false</value>
    </property>
    <property>
        <name>hive.exec.reducers.bytes.per.reducer</name>
        <value>128000000</value>
    </property>
    <property>
        <name>hive.exec.reducers.max</name>
        <value>99</value>
    </property>
</configuration>
